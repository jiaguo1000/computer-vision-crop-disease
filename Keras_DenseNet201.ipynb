{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 96
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1803,
     "status": "ok",
     "timestamp": 1584465407768,
     "user": {
      "displayName": "TIAN WU",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi52BHlJMYefqLzqNFmKNc1S1NGcMuRJBEpHiFS=s64",
      "userId": "02863650357663315545"
     },
     "user_tz": 240
    },
    "id": "mLqOMw7fsYxt",
    "outputId": "62b2c275-728c-41ee-a4f8-f16b385863aa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sys \n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization, GlobalMaxPooling2D, Concatenate\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "sys.path.append('..')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqpTf7jItNEJ"
   },
   "outputs": [],
   "source": [
    "#load tensorboard\n",
    "%load_ext tensorboard\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1783,
     "status": "ok",
     "timestamp": 1584465407773,
     "user": {
      "displayName": "TIAN WU",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi52BHlJMYefqLzqNFmKNc1S1NGcMuRJBEpHiFS=s64",
      "userId": "02863650357663315545"
     },
     "user_tz": 240
    },
    "id": "vXf1a4BAtXe1",
    "outputId": "2e5417ed-2613-49b3-a337-dafddbb5e3c7"
   },
   "outputs": [],
   "source": [
    "#see if we are in the right dir\n",
    "dir_root = \"/\"\n",
    "os.listdir(dir_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1773,
     "status": "ok",
     "timestamp": 1584465407774,
     "user": {
      "displayName": "TIAN WU",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi52BHlJMYefqLzqNFmKNc1S1NGcMuRJBEpHiFS=s64",
      "userId": "02863650357663315545"
     },
     "user_tz": 240
    },
    "id": "PG0H3STYuXR-",
    "outputId": "8b5d7582-977a-4b32-9744-4c88f73ef848"
   },
   "outputs": [],
   "source": [
    "#see if we are in the right dir\n",
    "os.listdir(dir_root+ \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooTCfXJLt8aR"
   },
   "outputs": [],
   "source": [
    "#calculate the weight of three classes by their frequencies\n",
    "def weight(data_root_dir):\n",
    "    leaf_rust_count = len(list(Path(data_root_dir + \"train/leaf_rust\").glob('*')))\n",
    "    stem_rust_count = len(list(Path(data_root_dir + \"train/stem_rust\").glob('*')))\n",
    "    healthy_wheat_count = len(list(Path(data_root_dir + \"train/healthy_wheat\").glob('*')))\n",
    "    total = leaf_rust_count + stem_rust_count + healthy_wheat_count\n",
    "\n",
    "    healthy_wheat_weight = (1/healthy_wheat_count) * (total) / 3.0\n",
    "    leaf_rust_weight = (1/leaf_rust_count) * (total) / 3.0\n",
    "    stem_rust_weight = (1/stem_rust_count) * (total) / 3.0\n",
    "    \n",
    "    class_weight = {0:healthy_wheat_weight, 1:leaf_rust_weight, 2:stem_rust_weight}\n",
    "    return class_weight\n",
    "    \n",
    "class_weight=weight(dir_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3AcHdmrtj1o"
   },
   "outputs": [],
   "source": [
    "#construct our transfer learning model from DenseNet-201 in Keras\n",
    "from keras.applications.densenet import DenseNet201\n",
    "def densenet201():\n",
    "    base_model = DenseNet201(include_top=False, weights='imagenet')    #do not need the top layer of DenseNet-201\n",
    "    x = base_model.output              #get the output tensor of DenseNet-201\n",
    "    x=GlobalMaxPooling2D()(x)      #pooling\n",
    "    x=BatchNormalization()(x)         #relieve overfitting\n",
    "    x=Dense(256, activation='relu')(x)     #fc layer to learn more information about the activation map of the transfer learning model\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128, activation='relu')(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    preds=Dense(3,activation='sigmoid')(x) #final layer with sigmoid activation\n",
    "    model = Model(inputs=base_model.input, outputs=preds)  #the input is that of the base_model and the output shape will be our prediction shape\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcSeFcI9wRMp"
   },
   "outputs": [],
   "source": [
    "#the data generator to generate augmented image data in order to relieve overfitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.15,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,  # set range for random shear\n",
    "    zoom_range=0.15,  # set range for random zoom\n",
    "    channel_shift_range=0.0,  # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,  # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True,  # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=1./255,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format='channels_last'\n",
    ")\n",
    "\n",
    "#for validation data, we just need to rescale without data augmentation\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    data_format='channels_last'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2083,
     "status": "ok",
     "timestamp": 1584465408124,
     "user": {
      "displayName": "TIAN WU",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi52BHlJMYefqLzqNFmKNc1S1NGcMuRJBEpHiFS=s64",
      "userId": "02863650357663315545"
     },
     "user_tz": 240
    },
    "id": "3OkQ24c3ty7Q",
    "outputId": "3e5da806-fceb-4188-a58f-1edaa8794f7d"
   },
   "outputs": [],
   "source": [
    "#early stopping callback\n",
    "callback = [keras.callbacks.EarlyStopping(monitor='val_loss',patience=4)]\n",
    "\n",
    "batch_size = 8\n",
    "#the image data and its label will flow from its directory, with a predefined batch size\n",
    "#shullfe=True is by default\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_root + 'train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    dir_root + 'validation',\n",
    "    target_size=(224, 224),\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1275191,
     "status": "ok",
     "timestamp": 1584466681241,
     "user": {
      "displayName": "TIAN WU",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi52BHlJMYefqLzqNFmKNc1S1NGcMuRJBEpHiFS=s64",
      "userId": "02863650357663315545"
     },
     "user_tz": 240
    },
    "id": "OeDTTvLtxfto",
    "outputId": "8b73110b-b3d1-474f-dfc8-b1eaead6d9f4"
   },
   "outputs": [],
   "source": [
    " model = densenet201()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=keras.optimizers.adam(lr=1e-4),  \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#fitting generator will save the memory consumed by our program. we include class_weight here to address the imbalanced dataset problem\n",
    "model.fit_generator(\n",
    "            train_generator, \n",
    "            steps_per_epoch = 700//batch_size+1,\n",
    "            epochs=20 ,\n",
    "            validation_data = validation_generator,\n",
    "            validation_steps = 176//batch_size+1,\n",
    "            callbacks=callback,\n",
    "            class_weight=class_weight)\n",
    " \n",
    " learning_rates = [1e-4, 1e-5, 1e-6]\n",
    " for lr in learning_rates: \n",
    "    #after having the data and architecture model, we need to compile it with loss function, optimizer and metrics\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=keras.optimizers.SGD(lr=lr, momentum=0.9),  \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    #fitting generator will save the memory consumed by our program. we include class_weight here to address the imbalanced dataset problem\n",
    "    model.fit_generator(\n",
    "                train_generator, \n",
    "                steps_per_epoch = 700//batch_size+1,\n",
    "                epochs=20 ,\n",
    "                validation_data = validation_generator,\n",
    "                validation_steps = 176//batch_size+1,\n",
    "                callbacks=callback,\n",
    "                class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWFDthDZ98Wa"
   },
   "outputs": [],
   "source": [
    "#creating the submission csv file\n",
    "def create_submission(model, name):\n",
    "    #import the Image module\n",
    "    from PIL import Image\n",
    "    def load_process(path):\n",
    "        path_str = str(path)\n",
    "        image = Image.open(path_str)\n",
    "        image.load()\n",
    "        image = np.asarray(image, dtype=\"float32\" ) #change the image into the nd-array\n",
    "        image /= 255.0 #rescale the image by dividing 255\n",
    "        image = image.reshape(-1,224,224,3) #add a more dimension\n",
    "        name = path.name.split('.')[0] #pick the name\n",
    "        return name, image\n",
    "\n",
    "    paired_name_image = list(map(load_process, list(Path(dir_root +'/test').glob('*'))))\n",
    "    index = [i[0] for i in paired_name_image]\n",
    "    probs = [model.predict(i[1])[0] for i in paired_name_image]\n",
    "    submission = pd.DataFrame(probs)\n",
    "    submission.index = index\n",
    "    submission.columns = ['healthy_wheat', 'leaf_rust', 'stem_rust']\n",
    "    submission = submission[['leaf_rust', 'stem_rust', 'healthy_wheat']]\n",
    "    submission.columns = ['leaf_rust', 'stem_rust', 'healthy_wheat']   #change the column order\n",
    "    submission.to_csv(\"/content/submission_\"+name+\".csv\")  #save the csv file into /content dir\n",
    "create_submission(model, \"DenseNet201\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dxAtTryHnFa"
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "def load_model(name):\n",
    "    from keras.models import model_from_json\n",
    "    json_file = open(\"/\"+name+\".json\", 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"/\"+model+\".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    " \n",
    "# save the model into json file and serialize the weights into h5 file\n",
    "def save_model(model, name):\n",
    "    \"\"\"\n",
    "    the first arg is the model object and the second arg is the name that you would like to store\n",
    "    \"\"\"\n",
    "    model_json = model.to_json()\n",
    "    with open(\"/\"+name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"/\"+name+\".h5\")\n",
    "    print(\"Saved model to disk\")\n",
    " \n",
    "#save_model(model, \"densenet201\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9p25tl1mOee"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP/5YH/icX4AyiYb7wxcVPN",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "2_DenseNet201.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
